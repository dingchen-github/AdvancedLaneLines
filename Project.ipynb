{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "# import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib tk \n",
    "# qt doesn\"t work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## camera calibration\n",
    "## Here I use the code from ../examples/example.ipynb\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane\n",
    "\n",
    "# Make a list of calibration images\n",
    "# images = glob.glob('/Users/Victoria/udacity-git-course/CarND/LaneLines/CarND-Advanced-Lane-Lines/camera_cal/calibration*.jpg')\n",
    "## Lesson: use the ABSOLUTE path!\n",
    "path = '/Users/Victoria/udacity-git-course/CarND/LaneLines/CarND-Advanced-Lane-Lines'\n",
    "images = []\n",
    "for i in range(1,21):\n",
    "    img_path = path + '/camera_cal/calibration' + str(i) + '.jpg'\n",
    "    img = cv2.imread(img_path)\n",
    "    images.append(img)\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for img in images:\n",
    "#    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        cv2.imshow('img',img)\n",
    "        cv2.waitKey(500)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# camera matrix and distortion coefficients\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, images[0].shape[1::-1], None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test camera calibration\n",
    "dst = cv2.undistort(images[1], mtx, dist, None, mtx)\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.set_title('Distorted')\n",
    "ax1.imshow(images[1], cmap='gray')\n",
    "ax2.set_title('Undistorted')\n",
    "ax2.imshow(dst, cmap='gray')\n",
    "plt.savefig(path + '/output_images/undistorted.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholding function\n",
    "def thresh(img, kernel_size=5, sobel_thresh=(100,200), mag_thresh=(10,255), direc_thresh=(0.7,1.3), S_thresh=(90,255)):\n",
    "    # Sobel function\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, kernel_size)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, kernel_size)\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    abs_sobely = np.absolute(sobely)\n",
    "    mag = np.sqrt(sobelx**2 + sobely**2) # magnitude of gradients\n",
    "    direc = np.arctan2(abs_sobely, abs_sobelx) # direction of gradients\n",
    "\n",
    "    # Convert the absolute value image to 8-bit\n",
    "    scaled_sobelx = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    scaled_sobely = np.uint8(255*abs_sobely/np.max(abs_sobely))\n",
    "    scaled_mag = np.uint8(255*mag/np.max(mag))\n",
    "\n",
    "    sxbinary = np.zeros_like(scaled_sobelx)\n",
    "    sxbinary[(scaled_sobelx >= sobel_thresh[0]) & (scaled_sobelx <= sobel_thresh[1])] = 1\n",
    "    sybinary = np.zeros_like(scaled_sobely)\n",
    "    sybinary[(scaled_sobely >= sobel_thresh[0]) & (scaled_sobely <= sobel_thresh[1])] = 1\n",
    "\n",
    "    mag_binary = np.zeros_like(mag)\n",
    "    mag_binary[(scaled_mag >= mag_thresh[0]) & (scaled_mag <= mag_thresh[1])] = 1\n",
    "\n",
    "    direc_binary = np.zeros_like(direc)\n",
    "    direc_binary[(direc >= direc_thresh[0]) & (direc <= direc_thresh[1])] = 1\n",
    "\n",
    "    # HLS color space\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    S = hls[:,:,2]\n",
    "    S_binary = np.zeros_like(S)\n",
    "    S_binary[(S > S_thresh[0]) & (S <= S_thresh[1])] = 1\n",
    "\n",
    "    # combine all conditions\n",
    "    combined = np.zeros_like(S)\n",
    "    combined[((sxbinary == 1) & (sybinary == 1)) | ((mag_binary == 1) & (direc_binary == 1)) & (S_binary == 1)] = 1\n",
    "    \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the thresholding function\n",
    "img = cv2.imread(path + '/test_images/straight_lines2.jpg')\n",
    "# parameter: 15, (100,200), (10,255), (0.7,1.3), (90,255)\n",
    "img_thresh = thresh(img)\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.set_title('Original')\n",
    "ax1.imshow(img, cmap='gray')\n",
    "ax2.set_title('Thresholding')\n",
    "ax2.imshow(img_thresh, cmap='gray')\n",
    "plt.savefig(path + '/output_images/straight_lines2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perspective transform function\n",
    "def warp(img, src, dst):\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    warped = cv2.warpPerspective(img, M, img_size, flags = cv2.INTER_LINEAR)\n",
    "\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the warp function\n",
    "path = '/Users/Victoria/udacity-git-course/CarND/LaneLines/CarND-Advanced-Lane-Lines'\n",
    "img = cv2.imread(path + '/test_images/straight_lines2.jpg')\n",
    "src = np.float32(\n",
    "    [[260,684],\n",
    "     [610,438],\n",
    "     [670,438],\n",
    "     [1070,684]])\n",
    "dst = np.float32(\n",
    "    [[270,720],\n",
    "     [270,0],\n",
    "     [1010,0],\n",
    "     [1010,720]])\n",
    "warped = warp(img, src, dst)\n",
    "\n",
    "# draw source points on image\n",
    "img_copy = np.copy(img)*0\n",
    "for i in range(-1,3):\n",
    "    cv2.line(img_copy,(src[i][0], src[i][1]),(src[i+1][0], src[i+1][1]), (255,0,0), 5)\n",
    "combo_src = cv2.addWeighted(img, 0.8, img_copy, 1, 0)\n",
    "\n",
    "# draw destination points on image\n",
    "warped_copy = np.copy(warped)*0\n",
    "for i in range(-1,3):\n",
    "    cv2.line(warped_copy,(dst[i][0], dst[i][1]),(dst[i+1][0], dst[i+1][1]), (255,0,0), 5)\n",
    "combo_warped = cv2.addWeighted(warped, 0.8, warped_copy, 1, 0)\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.set_title('Source image')\n",
    "ax1.imshow(combo_src, cmap='gray')\n",
    "ax2.set_title('Destination image')\n",
    "ax2.imshow(combo_warped, cmap='gray')\n",
    "plt.savefig(path + '/output_images/warped_straight_lines2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
